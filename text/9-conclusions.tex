\clearpage
\section*{\hfil ВЫВОДЫ \hfil}
\addcontentsline{toc}{section}{ВЫВОДЫ}
	В результате работы:
	\begin{itemize}
		\item Разработаны модификации архитектуры GAN для синтеза обозначенного множества текстур с трендами
		\item Полученные нейросети реализованы в виде комплекса программ
		\item Эффективность предложенного подхода была исследована в ходе вычислительных экспериментов с использованием синтетических данных
	\end{itemize}
	Результаты синтеза, полученные на первых двух выборках, показывают, что генеративные модели, основанные на состязательных сетях, могут обучиться синтезировать объекты с протяженной в пространстве коррелляцией. Однако, обучение глубоких нейронных сетей остается сложной в плане подбора параметров задачей. Это видно на примере результатов сетей, обученных на выборках 3 и 4, которые не смогли обучиться синтезу изображения с трендом и сошлись к некоторому локальному минимуму, соответствующему средней по выборке интенсивности частиц. Поскольку нейронные сети не являются интерпретируемым алгоритмом машинного обучения, то сказать, почему именно так произошло сложно и требует отдельных экспериментов.
	
	Качество синтезируемых изображений с точки зрения повторения тренда интенсивности не идеально. Для улучшения качества нужно провести дополнительные эксперименты, с обучением на большем объеме данных и/или более сложных моделей. На основе же полученных результатов можно выдвинуть предположения, что оптимальным с точки зрения скорости обучения и качества синтезированных текстур значением параметра nf (число фильтров на первом сверточном слое) равно 32, а значение параметра $\eta$, отвечающего за баланс между $L_{adv}$ и $L1$ в итоговом функционале потерь, не имеет решающего значения.