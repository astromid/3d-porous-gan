\clearpage
\section*{\hfil ВВЕДЕНИЕ \hfil}
	
	В настоящее время для эффективной добычи полезных ископаемых (в частности, нефти и газа) широко применяется математическое моделирование для симуляции процессов переноса, происходящих в пласте. При этом, прямое моделирование невозможно как минимум из-за неполноты данных о среде, в которой эти процессы протекают (знаний о структуре и геометрии пласта). Эти данные доступны только в некотором количестве точек (скважин), из которых забирают пробу среды - керн. Керны представляют собой очень небольшой объем среды; если же говорить о данных компьютерной томографии керна, то она доступна на ещё более мелких масштабах - порядка микрометров. Получение дополнительных данных (например, новых кернов, компьютерной томографии) связано с большими затратами; при этом, многие эксперименты в реальности с керном можно провести только один раз, поскольку они необратимо влияют на керн. Таким образом, возникает проблема ``апскейлинга'' - правдоподобного переноса знаний о локальной структуре среды на большие масштабы, а так же проблема переиспользования керна для проведения разных экспериментов.
	
	В последнее время исследуется возможность применения методов машинного обучения для решения задач в этой области. Одним из возможных подходов является реконструкция новых моделей геометрии среды на основе реальных образцов с использованием искусственных нейронных сетей. Керны на микромасштабе являются пористой средой, поэтому наличие устойчивого алгоритма реконструкции образцов пористой среды позволит:
	
	\begin{itemize}
		\item попробовать провести апскейлинг (реконструировать среду в большем размере, чем оригинальный доступный образец)
		\item проводить статистические эксперименты (моделировать процессы не только на оригинальном образце, но и на его реконструкциях, получая таким образом распределение а, не значение в одной точке)
	\end{itemize}

	
	Под образцом пористой среды в данном случае понимаются данные компьютерной томографии керна - трёхмерное бинарное изображение.
	
	Широко известны подходы к задачам синтеза двухмерных изображений с помощью искусственных нейросетей \cite{Gatys, Ulyanov}, что мотивирует попробовать применить ИНС для задач реконструкции 3D-изображений.
	
	Математически сформулировать постановку такой задачи реконструкции можно с помощью так называемой вероятностной постановки задачи обучения \cite{Vorontsov, Goodfellow}.
	
	Рассмотрим многомерное пространство $X$, содержащее множество всех трёхмерных бинарных изображений $x$: $X = \{x\}$. Пусть у нас есть обучающая выборка из изображений, содержащих в себе рассматриваемое множество интересующих нас образцов $D = \{x_i\}$. Тогда считается, что  обучающая выборка изображений $D$ задаёт в этом пространстве вероятностное распределение $P_X : X \longrightarrow [0,1]$, устроенное таким образом, что точки, соответствующие изображениям из выборки, имеют высокую вероятность, а остальные - низкую. Таким образом задача реконструкции образца пористой среды сводится к синтезу случайного изображения $x'$, принадлежащего распределению, близкому к задаваемому обучающей выборкой:
	$$ P_{X'} \approx P_X, \quad x' \sim X'$$
	
	``Классический'' статистический подход к решению подобного рода задач заключается в введении параметризированного семейства распределений вероятности и его подстройке на имеющихся данных:
	
	\begin{itemize}
		\item Вводится семейство распределений вероятности $P_{\theta}(x)$ с параметром $\theta$
		\item Параметр $\theta$ находятся из обучающей выборки:
		$$ \mathcal{L}_{\theta}(D) = \prod_{x \in D} P_{\theta}(x) $$
		$$ \theta^{*} = \underset{\theta}{\arg\max} \mathcal{L}_{\theta}(D)$$
		\item Генерируется объект (изображение) из распределения $ P_{\theta^{*}}$
	\end{itemize}
	
	Этот подход подвержен проблемам:
	
	\begin{itemize}
		\item Пространство параметров $\theta$ может быть огромной размерности
		\item Для сложных случаев невозможно априорно задать модель распределения
	\end{itemize}
	
	Простой пример объекта со сложным пространством параметров - человеческое лицо. Задачу генерации изображения реалистичного человеческого лица долгое время не могли решить с удовлетворительным качеством. Однако последние достижения в области искусственных нейронных сетей привели к существенному улучшению качества генеративных моделей самого разнообразного типа. В частности, впечатляющие результаты были достигнуты с помощью генеративных состязательных сетей (GAN) \cite{Mirza, Gauthier, Zhao, Berthelot}, что мотивирует попытку применения нейросетей этой архитектуры в поставленной задаче.
	
	\subsection*{Постановка задачи}
	
	Для достижения обозначенных целей, поставить задачу данной работы можно так:
	
	\begin{itemize}
		\item Реализовать модифицированные для реконструкции образцов пористых сред архитектуры нейронных сетей
		\item Провести вычислительные эксперименты, связанные с обучением нейросетей (то есть, с решением задач многопараметрической оптимизации)
		\item Реконструировать с помощью обученных нейросетей новые образцы и провести их верификацию
	\end{itemize}

	Верификация реконструированных образцов основана на сохранении их топологических и статистических характеристик, а именно:
	
	\begin{itemize}
		\item Топологические: 4 первых функционала Минковского:
		\begin{itemize}
			\item Объем
			\item Площадь поверхности
			\item Средняя кривизна
			\item Характеристика Эйлера-Пуанкаре
		\end{itemize}
		\item Статистические: двухточечная корреляционная функция
	\end{itemize}

	Подробное описание процедур верификации и используемых характеристик приведено в разделе 3.
	
	\subsection*{Предшествующие работы}
		Рассмотренный подход к задаче уже исследовался \cite{Mosser}. В этой статье авторы используют архитектуры DCGAN \cite{Radford} и 3D-GAN \cite{Wu} для решения задачи реконструкции пористых сред. Один из своих экспериментов авторы проводили на тех же данных компьютерной томографии, что и в этой работе, что позволяет сравнивать полученные результаты. Основное отличие данной работы от \cite{Mosser} заключается модификации процедуры обучения сетей для автоматического управления одним из гиперпараметров обучения - шага обучения (learning rate, LR). Более подробно модификация описана в разделе 1.4.4