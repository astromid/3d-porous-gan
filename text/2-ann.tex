\clearpage
\section{Нейронные сети}
	ИНС - искусственная нейронная сеть - это математическая модель, построенная по принципу организации и функционирования биологических нейронных сетей. Она представляет собой систему соединённых простых блоков - искусственных нейронов, каждый из которых имеет входы и выходы для взаимодействия с другими нейронами. Главное преимущество нейронных сетей перед традиционными алгоритмами в том, что они обучаются на некотором наборе данных, а не программируются в классическом смысле этого понятия. Процесс обучения заключается в нахождении оптимальных весовых коэффициентов между нейронами. С математической точки зрения, процесс обучения - это задача многопараметрической нелинейной оптимизации.
	\subsection{Математическая модель нейрона}
		Одиночный нейрон обычно представляет собой взвешенный сумматор с нелинейной функцией активации на выходе:
		$$x_{out} = \phi(\vec{w} \cdotp \vec{x}_{in}),$$
		где $\vec{w}$ - вектор весовых коэффициентов связей, $\vec{x}_{in}$ - входной вектор, $\phi$ - нелинейная функция активации (Рис. \ref{3-artificial-neuron-model}).
		
		\begin{figure}[h]
			\centering{\includegraphics[width=0.95\linewidth]{3-ann/artificial-neuron-model}}
			\caption{Математическая модель нейрона}
			\label{3-artificial-neuron-model}
		\end{figure}
		
		Функции активации могут выбираться разными в зависимости от задачи. Наиболее часто используемые функции:
		
		\begin{itemize}
			\item Сигмоида (логистическая функция)
					$$\sigma(x) = \frac{1}{1 + e^{-x}}$$
			\item Гиперболический тангенс
			\item ReLU
					$$ReLU(x) = \max(0, x)$$
			\item softmax
					$$\sigma(\vec{x})_j = \frac{e^{x_j}}{\sum_{k=1}^{N} e^{z_k}}$$
		\end{itemize}
		Множество подобных нейронов соединяется в сеть и обучается с помощью метода обратного распространения ошибки вкупе с каким-либо методом численной оптимизации.
	\subsection{Метод обратного распространения ошибки}
		Метод обратного распространения ошибки (backpropagation) - самый широко используемый и успешный алгоритм обучения глубоких (многослойных) нейронных сетей. Суть метода заключается в распространении сигналов ошибки от выходов сети к ее входам в обратном к распространению сигнала в сети направлении. Это позволяет вычислить производные функционала ошибки по весам сети, которые потом можно использовать в любом градиентном алгоритме оптимизации (например, градиентном спуске).
		
		Обозначим множество входов сети как $\{x_1, \ldots, x_n\}$, множество выходов - $O$, $w_{ij}$ - вес, присвоенный ребру, соединяющему $i$-й и $j$-й узлы, $y_k$ - известные (правильные) ответы, $o_i$ - выход $i$-го узла. Введём функцию ошибки (например, сумма квадратов расстояний):
		$$ L(\vec{x}, W) = \frac{1}{2} \sum_{k \in O} (y_k - o_k)^2, $$
		где $W = \{w_{ij}\}$ - матрица весовых коэффициентов
		
		Рассмотрим сначала нейроны последнего слоя. Весовой коэффициент $w_{ij}$ влияет на выход сети как часть суммы $S_j = \sum_i w_{ij} x_i$. Соответственно,
		$$ \frac{\partial L}{\partial w_{ij}} = \frac{\partial L}{\partial S_j} \frac{\partial S_j}{\partial w_{ij}} = x_i \frac{\partial L}{\partial S_j} $$
		
		Аналогично, $S_j$ влияет на общую ошибку только в рамках выхода $j$-го узла $o_j$, поэтому
		$$ \frac{\partial L}{\partial S_j} = \frac{\partial L}{\partial o_j} \frac{\partial o_j}{\partial S_j}  = \left(\frac{\partial}{\partial o_j} \frac{1}{2} \sum_{k \in Out} (y_k - o_k)^2 \right) \left(\frac{\partial \phi(S)}{\partial S} \bigg|_{S = S_j} \right)$$
		Если узел $j$ не находится на последнем слое, то у него есть набор связей с нейронами следующего слоя. Обозначим их множество как $K_j$. Тогда
		$$ \frac{\partial L}{\partial S_j} = \sum_{k \in K_j} \frac{\partial L}{\partial S_k} \frac{\partial S_k}{\partial S_j} $$
		$$ \frac{\partial S_k}{\partial S_j} = \frac{\partial S_k}{\partial o_j} \frac{\partial o_j}{\partial S_j} = w_{jk}\frac{\partial o_j}{\partial S_j} $$
		$ \frac{\partial L}{\partial S_k}$ - аналогичная поправка, но для нейрона следующего слоя. В итоге, получены выражения для производных ошибки по весам для нейронов выходного слоя, а аналогичные производные для нейронов внутренних слоев выражены через нейроны следующих слоев. Это и есть процесс обратного распространения ошибки - градиенты ошибки по весам вычисляются последовательно, начиная с выходного слоя и заканчивая первым.
	\subsection{Сверточные нейронные сети}
		Сверточные нейронные сети (CNN - convolutional neural networks) - это специальная архитектура нейронной сети, нацеленная на эффективное распознавание изображений, впервые предложенная Яном Лекуном \cite{LeCun}. Структура такой сети имеет некоторое сходство со строением зрительной коры головного мозга. Свое название CNN получили из-за наличия сверточных слоев, в которых каждый фрагмент изображения умножается на ядро свертки, полученный результат суммируется и записывается в аналогичную позицию выходного изображения. Одно отдельное ядро свертки обычно интерпретируют как кодирование какого-либо признака изображения. При этом сами ядра выучиваются сетью самостоятельно, а не закладываются человеком. В CNN чередуются сверточные и субдискретизирующие слои, таким образом более глубокие сверточные слои могут выделять абстрактные детали изображения, вплоть до общих понятий, таких как ``кошка'', ``собака'', и т.п. На данный момент CNN являются наиболее популярным алгоритмом машинного обучения при работе с изображениями.
	\subsection{Генеративные состязательные сети}
		Архитектура нейронной сети, получившая название генеративной состязательной сети (generative adversarial network - GAN), впервые была описана в 2014 году \cite{Goodfellow}. За последнее время сети такого типа добились больших успехов в задачах синтеза объектов из сложных распределений. Этим объясняется мотивация попытки применения данной архитектуры для решения поставленной задачи.
		\subsubsection{Общая структура}
			Переформулируем изначальную задачу нахождения процедуры синтеза $X'$ такой что $ P_{X'} \approx P_X$:
			$$ \rho(P_{X'}, P_X) \longrightarrow \underset{P_{X'}}{\min} $$
			Введём параметризированную процедуру генерации:
			$$ X' = g_{\theta}(\cdot) $$
			Получаем:
			$$ \rho(P_{X'}, P_X) \longrightarrow \underset{P_{X'}}{\min} $$
			$$ \rho(g_{\theta}(\cdot), P_X) \longrightarrow \underset{g_{\theta}(\cdot)}{\min} $$
			$$ \rho(g_{\theta}(\cdot), P_X) \longrightarrow \underset{\theta}{\min} $$
			В данном случае $\rho$ выступает некоторой метрикой похожести двух вероятностных распределений.
			Идея GAN заключается в том, что в качестве такой метрики используется функционал ошибки другой нейросети -  обученного классификатора: чем чаще ошибается обученный классификатор, тем больше одно распределение похоже на другое. Тогда задача принимает вид:
			$$ \rho(P_{X'}, P_X) \longrightarrow \min \Leftrightarrow L \longrightarrow \max, $$
			где $L$ - функция потерь обученного классификатора.
			Соответственно, вводятся две нейросети:
	
			\begin{itemize}
				\item $d_{\zeta}(x)$ - классификатор для оценки $\rho$, ``дискриминатор''
				\item $g_{\theta}(x)$ - сеть, трансформирующая шум в элементы множества $X'$, ``генератор''
			\end{itemize}
	
			Суть использования двух сетей состоит в том, что они обучаются совместно, конкурируя друг с другом: генератор пытается имитировать целевое распределение, а дискриминатор классифицирует поступающие от генератора и из обучающей выборки изображения на 2 класса: реальные (из изначального распределения $P_X$) и ложные (из $P_{X'}$, т.е. синтезированные генератором). Сигнал от дискриминатора возвращается в генератор и используется для обучения генератора ``обману'' дискриминатора.
			Для дальнейшего рассмотрения введём функцию потерь дискриминатора (BCE - binary cross-entropy, logloss):
			$$ l_1 = l(d_{\zeta}(x), 1) $$
			$$ l_2 = l(d_{\zeta}(x'), 0) $$
			$$ L(X, X') = \frac{1}{2} \mathbb{E}_{X} l_1 + \frac{1}{2} \mathbb{E}_{X'} l_2 = -\frac{1}{2} (\mathbb{E}_{X} \log d_{\zeta}(x) + \mathbb{E}_{X'} \log (1 - d_{\zeta}(x'))) = $$
			$$ =  -\frac{1}{2} (\mathbb{E}_{X} \log d_{\zeta}(x) + \mathbb{E}_{V} \log (1 - d_{\zeta}(g_{\theta}(v)))) = L(\zeta, \theta) .$$
			Функция потерь обученного классификатора:
			$$ L^*(\theta) = \underset{\zeta}{\min} L(\zeta, \theta) $$
			Соответственно,
			$$ \underset{\zeta}{\min} L(\zeta, \theta) \longrightarrow \underset{\theta}{\max} $$
			$$ \theta^* = \underset{\theta}{\arg\max} \left[ \underset{\zeta}{\min} L(\zeta, \theta) \right] $$
			Определим оптимальный дискриминатор:
			$$ d^*_{\theta} = d_{\zeta^*(\theta)} $$
			$$ \zeta^*(\theta) =  \underset{\zeta}{\arg\min} L(\zeta, \theta)$$
			
		\subsubsection{Обучение GAN}
			Итак, задача обучения GAN свелась к нахождению оптимальных весов генератора
			$$ \theta^* = \underset{\theta}{\arg\max} \left[ \underset{\zeta}{\min} L(\zeta, \theta) \right] $$
			Процесс обучения такой системы сетей принимает итеративный вид:
	
			\begin{itemize}
				\item Обучается дискриминатор при фиксированном генераторе
				\item Обучается генератор при фиксированном дискриминаторе
				\item Повторяется до сходимости параметров обеих моделей
			\end{itemize}
			Описанный процесс схематично изображён на (Рис. \ref{2-gan-training}).
	
			\begin{figure}[h!]
				\centering{\includegraphics[width=0.4\linewidth]{3-ann/gan-training}}
				\caption{Схематическое изображение процесса обучения GAN}
				\label{2-gan-training}
			\end{figure}
	
		\subsubsection{Модификации ``DCGAN'' и ``3D-DCGAN''}
			Модификация архитектуры GAN под названием DCGAN \cite{Radford} была предложена в 2015 году и совершила прорыв в области синтеза изображений. Суть архитектуры заключается в нескольких принципах построения сетей и их обучания. Во-первых, использование свёрточных слоев и пакетной нормализации (batch normalization)  как в генераторе, так и дискриминаторе. В генераторе, при этом, используются специальные обратные свёрточные слои (transposed convolution, deconvolution). Во-вторых, использование специальной функции активации в дискриминаторе - $LeakyReLU$:
			\[ LeakyReLU(x) = \left \{ \begin{array}{rcl} 0.01 x & \mbox{for} & x < 0\\ x & \mbox{for} & x \ge 0\end{array} \right .\]  
			Все эти идеи позволяют стабилизировать сложный процесс обучения GAN и увеличить качество синтезируемых объектов.
			
			Архитектура 3D-DCGAN совмещает в себе идеи \cite{Radford} и \cite{Wu}. Основное отличие от обычной DCGAN состоит в том, что вместо двухмерных свёрток во всех свёрточных слоях сетей используются трёхмерные, что и позволяет реконструировать трёхмерные среды.
			
			Авторы \cite{Mosser} используют 3D-DCGAN для реконструкции пористых сред. Схема процесса обучения показана на (Рис. \ref{2-gan-scheme})
			
			\begin{figure}[h!]
				\centering{\includegraphics[width=0.8\linewidth]{3-ann/GAN_overview}}
				\caption{Схема процесса обучения}
				\label{2-gan-scheme}
			\end{figure}
		
			Обучение 3D-GAN сводится к минимизации функционала:
			\[ \underset{\theta}{\min} \underset{\zeta}{\max} \ \mathbb{E}_{x \sim p_{data}}\log D_\zeta(x) + \mathbb{E}_{z \sim p_{z}} \log (1 - D_\zeta(G_\theta(z))) \]
		
		\subsubsection{Модификация процедуры обучения}
			Сеть, использованная в этой работе, полностью повторяет архитектуру сетей \cite{Mosser}, однако в процедуру обучения сетей внесена модификация.
			
			Скорость обучения - один из наиболее важных гиперпараметров (параметров, которые задаются человеком, а не оптимизируются в ходе процесса обучения). Её значение может радикально влиять на весь процесс сходимости сети \cite{Smith}. В \cite{Mosser} авторы вручную управляют значением скорости обучения, изменяя её в зависимости от рассчитанных функционалов Минковского и визуальной структуры реконструируемых образцов. Это видно на графике профиля обучения сетей, приведённом в \cite{Mosser} (Рис. \ref{2-berea-curve}):
			
			\begin{figure}[h!]
				\centering{\includegraphics[width=1\linewidth]{3-ann/berea_training_curve}}
				\caption{Схема процесса обучения \cite{Mosser}}
				\label{2-berea-curve}
			\end{figure}
		
			В этой работе исследуется применение модификации процедуры обучения, которая состоит в том, что:
			
			\begin{itemize}
				\item Значения функционалов Минковского рассчитываются для реконструированных образцов на каждой итерации процесса обучения, что позволяет отслеживать текущее состояние сети-генератора с точки зрения совпадения топологических характеристик образцов с желаемыми;
				\item Это позволяет после каждого шага обучения оценить невязку $\Delta_i$:
					\[ \Delta_i = |B_i - B_{berea}| + |\xi_i - \xi_{berea}|, \]
					где $B_i$, $\xi_i$ - это значения соответствующих функционалов Минковского для реконструированного образца с помощью генератора на текущем шаге обучения, а $B_{berea}$ и $\xi_{berea}$ - значения этих функционалов для исходного образца.
			\end{itemize}
			Если значение $\Delta_i$ не меняется более 3000 итераций, то скорость обучения уменьшается в 10 раз.